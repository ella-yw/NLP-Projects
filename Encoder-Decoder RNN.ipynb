{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "FU7xWiY6TyWS"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "!(stat -t /usr/local/lib/*/dist-packages/google/colab > /dev/null 2>&1) && exit\n",
        "rm -rf 68611-hw2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5AyMA9rK1Rhf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"68611-hw2\", exist_ok=True)\n",
        "import sys\n",
        "sys.path.append(\"/content/68611-hw2\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL1IfnRdPdsl",
        "outputId": "efb70eaf-e73f-40f3-fb28-c30985f34c2f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.3.1-py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.9/118.9 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting portalocker (from sacrebleu)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (1.23.5)\n",
            "Collecting colorama (from sacrebleu)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n",
            "Installing collected packages: portalocker, colorama, sacrebleu\n",
            "Successfully installed colorama-0.4.6 portalocker-2.8.2 sacrebleu-2.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install sacrebleu"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilKcWfSHYltK"
      },
      "source": [
        "# **Part 0: Data Loading and Preprocessing**\n",
        "\n",
        "In this section we will load the data that we will be using throughout the lab and perform some preprocessing steps. We will also define some functions that will be useful for training and evaluating your models. You do not need to write any code for this part, but you are encouraged to read through the code carefully and make sure you understand it.\n",
        "\n",
        "First we download the data. The dataset consists of parallel English and Vietnamese sentences (IWSLT'15 English-Vietnamese translation data). In the first two parts of the lab, you will do language modeling using only the English data, and in the final part of the lab you will do translation from Vietnamese to English."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rhqzGV7qZD2d",
        "outputId": "f0e2b3d2-aca4-4ab8-81bc-21cb858b6dd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2023-10-11 21:15:51 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en [13603614/13603614] -> \"/content/68611-hw2/train.en\" [1]\n",
            "2023-10-11 21:15:55 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi [18074646/18074646] -> \"/content/68611-hw2/train.vi\" [1]\n",
            "2023-10-11 21:15:56 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en [132264/132264] -> \"/content/68611-hw2/tst2013.en\" [1]\n",
            "2023-10-11 21:15:57 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi [183855/183855] -> \"/content/68611-hw2/tst2013.vi\" [1]\n",
            "2023-10-11 21:15:58 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.en [139741/139741] -> \"/content/68611-hw2/vocab.en\" [1]\n",
            "2023-10-11 21:15:58 URL:https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi [46767/46767] -> \"/content/68611-hw2/vocab.vi\" [1]\n"
          ]
        }
      ],
      "source": [
        "# Download data\n",
        "!wget -nv -O /content/68611-hw2/train.en https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.en\n",
        "!wget -nv -O /content/68611-hw2/train.vi https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/train.vi\n",
        "!wget -nv -O /content/68611-hw2/tst2013.en https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.en\n",
        "!wget -nv -O /content/68611-hw2/tst2013.vi https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/tst2013.vi\n",
        "!wget -nv -O /content/68611-hw2/vocab.en https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.en\n",
        "!wget -nv -O /content/68611-hw2/vocab.vi https://nlp.stanford.edu/projects/nmt/data/iwslt15.en-vi/vocab.vi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EUZEwI8ksBe"
      },
      "source": [
        "Next we read and store the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FzanSf24ZTJa"
      },
      "outputs": [],
      "source": [
        "def read_sentence_file(filename):\n",
        "  sentences_list = []\n",
        "  with open(filename, \"r\") as f:\n",
        "    for line in f:\n",
        "      sentences_list.append(line.strip().split())\n",
        "  return sentences_list\n",
        "\n",
        "def read_vocab_file(filename):\n",
        "  with open(filename, \"r\") as f:\n",
        "    return [line.strip() for line in f]\n",
        "\n",
        "\n",
        "src_vocab_set = read_vocab_file(os.path.join(\"/content/68611-hw2\", \"vocab.vi\"))\n",
        "trg_vocab_set = read_vocab_file(os.path.join(\"/content/68611-hw2\", \"vocab.en\"))\n",
        "\n",
        "train_src_sentences_list = read_sentence_file(os.path.join(\"/content/68611-hw2\",\n",
        "                                                           \"train.vi\"))\n",
        "train_trg_sentences_list = read_sentence_file(os.path.join(\"/content/68611-hw2\",\n",
        "                                                           \"train.en\"))\n",
        "assert len(train_src_sentences_list) == len(train_trg_sentences_list)\n",
        "\n",
        "test_src_sentences_list = read_sentence_file(os.path.join(\"/content/68611-hw2\",\n",
        "                                                          \"tst2013.vi\"))\n",
        "test_trg_sentences_list = read_sentence_file(os.path.join(\"/content/68611-hw2\",\n",
        "                                                          \"tst2013.en\"))\n",
        "assert len(test_src_sentences_list) == len(test_trg_sentences_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yo11GNvikUPl"
      },
      "source": [
        "Next we do preprocessing on the dataset, and we perform a preliminary data analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "id": "dO2t7gaAZvSc",
        "outputId": "32ff6c95-18eb-4ddb-c0ac-8a3ca2c5cab7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of training (src, trg) sentence pairs: 108748\n",
            "Number of validation (src, trg) sentence pairs: 12083\n",
            "Number of testing (src, trg) sentence pairs: 1139\n",
            "Size of en vocab set (including '<pad>', '<unk>', '<s>', '</s>'): 7710\n",
            "Size of vi vocab set (including '<pad>', '<unk>', '<s>', '</s>'): 17192\n",
            "Training sentence avg. length: 20 \n",
            "Training sentence length at 95-percentile: 42\n",
            "Training sentence length distribution (x-axis is length range and y-axis is count):\n",
            "\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Example Vietnamese input: ['Adam', 'Sadowsky', 'dàn', 'dựng', '1', 'video', 'âm', 'nhạc', 'hiện', 'tượng', '.']\n",
            "Its target English output: ['Adam', 'Sadowsky', ':', 'How', 'to', 'engineer', 'a', 'viral', 'music', 'video']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "MAX_SENT_LENGTH = 48\n",
        "MAX_SENT_LENGTH_PLUS_SOS_EOS = 50\n",
        "\n",
        "# We only keep sentences that do not exceed 48 words, so that later when we\n",
        "# add <s> and </s> to a sentence it still won't exceed 50 words.\n",
        "def filter_data(src_sentences_list, trg_sentences_list, max_len):\n",
        "  new_src_sentences_list, new_trg_sentences_list = [], []\n",
        "  for src_sent, trg_sent in zip(src_sentences_list, trg_sentences_list):\n",
        "    if (len(src_sent) <= max_len and len(trg_sent) <= max_len\n",
        "        and len(src_sent) > 0 and len(trg_sent)) > 0:\n",
        "      new_src_sentences_list.append(src_sent)\n",
        "      new_trg_sentences_list.append(trg_sent)\n",
        "  return new_src_sentences_list, new_trg_sentences_list\n",
        "\n",
        "train_src_sentences_list, train_trg_sentences_list = filter_data(\n",
        "    train_src_sentences_list, train_trg_sentences_list, max_len=MAX_SENT_LENGTH)\n",
        "test_src_sentences_list, test_trg_sentences_list = filter_data(\n",
        "    test_src_sentences_list, test_trg_sentences_list, max_len=MAX_SENT_LENGTH)\n",
        "\n",
        "# We take 10% of the training data to be the validation set.\n",
        "num_val = int(len(train_src_sentences_list) * 0.1)\n",
        "val_src_sentences_list = train_src_sentences_list[:num_val]\n",
        "val_trg_sentences_list = train_trg_sentences_list[:num_val]\n",
        "train_src_sentences_list = train_src_sentences_list[num_val:]\n",
        "train_trg_sentences_list = train_trg_sentences_list[num_val:]\n",
        "\n",
        "# Show some data stats\n",
        "print(\"Number of training (src, trg) sentence pairs: %d\" %\n",
        "      len(train_src_sentences_list))\n",
        "print(\"Number of validation (src, trg) sentence pairs: %d\" %\n",
        "      len(val_src_sentences_list))\n",
        "print(\"Number of testing (src, trg) sentence pairs: %d\" %\n",
        "      len(test_src_sentences_list))\n",
        "src_vocab_set = ['<pad>'] + src_vocab_set\n",
        "trg_vocab_set = ['<pad>'] + trg_vocab_set\n",
        "print(\"Size of en vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d\" %\n",
        "      len(src_vocab_set))\n",
        "print(\"Size of vi vocab set (including '<pad>', '<unk>', '<s>', '</s>'): %d\" %\n",
        "      len(trg_vocab_set))\n",
        "\n",
        "length = [len(sent) for sent in train_src_sentences_list]\n",
        "print('Training sentence avg. length: %d ' % np.mean(length))\n",
        "print('Training sentence length at 95-percentile: %d' %\n",
        "      np.percentile(length, 95))\n",
        "print('Training sentence length distribution '\n",
        "      '(x-axis is length range and y-axis is count):\\n')\n",
        "plt.hist(length, bins=5)\n",
        "plt.show()\n",
        "\n",
        "print('Example Vietnamese input: ' + str(train_src_sentences_list[0]))\n",
        "print('Its target English output: ' + str(train_trg_sentences_list[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vQI_A47IlPmO"
      },
      "source": [
        "Here we setup our PyTorch environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "oBNOk0XbZ4i4"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "#assert device == \"cuda\"   # use gpu whenever you can!\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znPbxQJvleTJ"
      },
      "source": [
        "We define custom dataset classes for both the language modeling task and the machine translation task so that we can use PyTorch's built-in dataset tools."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hYtacoWTaTms"
      },
      "outputs": [],
      "source": [
        "from torch.utils import data\n",
        "\n",
        "\n",
        "# These IDs are reserved.\n",
        "PAD_INDEX = 0\n",
        "UNK_INDEX = 1\n",
        "SOS_INDEX = 2\n",
        "EOS_INDEX = 3\n",
        "\n",
        "class LMDataset(data.Dataset):\n",
        "  def __init__(self, src_sentences, src_vocabs, sampling=1.):\n",
        "    self.src_sentences = src_sentences[:int(len(src_sentences) * sampling)]\n",
        "\n",
        "    self.max_src_seq_length = MAX_SENT_LENGTH_PLUS_SOS_EOS\n",
        "\n",
        "    self.src_vocabs = src_vocabs\n",
        "\n",
        "    self.src_v2id = {v : i for i, v in enumerate(src_vocabs)}\n",
        "    self.src_id2v = {val : key for key, val in self.src_v2id.items()}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.src_sentences)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    sent = self.src_sentences[index]\n",
        "    sent_len = len(sent) + 2   # add <s> and </s> to each sentence\n",
        "    sent_id = []\n",
        "    for w in sent:\n",
        "      if w not in self.src_vocabs:\n",
        "        w = '<unk>'\n",
        "      sent_id.append(self.src_v2id[w])\n",
        "    src_id = ([SOS_INDEX] + sent_id + [EOS_INDEX] + [PAD_INDEX] *\n",
        "              (self.max_src_seq_length - sent_len))\n",
        "    trg_id = (sent_id + [EOS_INDEX] + [PAD_INDEX] *\n",
        "              (self.max_src_seq_length - sent_len + 1))\n",
        "\n",
        "    return torch.tensor(src_id), sent_len, torch.tensor(trg_id), sent_len\n",
        "\n",
        "class MTDataset(data.Dataset):\n",
        "  def __init__(self, src_sentences, src_vocabs, trg_sentences, trg_vocabs,\n",
        "               sampling=1.):\n",
        "    self.src_sentences = src_sentences[:int(len(src_sentences) * sampling)]\n",
        "    self.trg_sentences = trg_sentences[:int(len(src_sentences) * sampling)]\n",
        "\n",
        "    self.max_src_seq_length = MAX_SENT_LENGTH_PLUS_SOS_EOS\n",
        "    self.max_trg_seq_length = MAX_SENT_LENGTH_PLUS_SOS_EOS\n",
        "\n",
        "    self.src_vocabs = src_vocabs\n",
        "    self.trg_vocabs = trg_vocabs\n",
        "\n",
        "    self.src_v2id = {v : i for i, v in enumerate(src_vocabs)}\n",
        "    self.src_id2v = {val : key for key, val in self.src_v2id.items()}\n",
        "    self.trg_v2id = {v : i for i, v in enumerate(trg_vocabs)}\n",
        "    self.trg_id2v = {val : key for key, val in self.trg_v2id.items()}\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.src_sentences)\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    src_sent = self.src_sentences[index]\n",
        "    src_len = len(src_sent) + 2   # add <s> and </s> to each sentence\n",
        "    src_id = []\n",
        "    for w in src_sent:\n",
        "      if w not in self.src_vocabs:\n",
        "        w = '<unk>'\n",
        "      src_id.append(self.src_v2id[w])\n",
        "    src_id = ([SOS_INDEX] + src_id + [EOS_INDEX] + [PAD_INDEX] *\n",
        "              (self.max_src_seq_length - src_len))\n",
        "\n",
        "    trg_sent = self.trg_sentences[index]\n",
        "    trg_len = len(trg_sent) + 2\n",
        "    trg_id = []\n",
        "    for w in trg_sent:\n",
        "      if w not in self.trg_vocabs:\n",
        "        w = '<unk>'\n",
        "      trg_id.append(self.trg_v2id[w])\n",
        "    trg_id = ([SOS_INDEX] + trg_id + [EOS_INDEX] + [PAD_INDEX] *\n",
        "              (self.max_trg_seq_length - trg_len))\n",
        "\n",
        "    return torch.tensor(src_id), src_len, torch.tensor(trg_id), trg_len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6xfQ4PSYl1Jz"
      },
      "source": [
        "Next we instantiate our datasets and data loaders. The data loaders are what we will iterate over when training and evaluating our models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CR8M8apZivz-",
        "outputId": "2efb6442-8be6-4c88-bbe3-bb5b65785cb0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128 # note that this is a hyperparameter you may want to adjust\n",
        "\n",
        "lm_train_set = LMDataset(train_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "lm_train_data_loader = data.DataLoader(lm_train_set, batch_size=batch_size,\n",
        "                                      num_workers=8, shuffle=True)\n",
        "\n",
        "lm_val_set = LMDataset(val_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "lm_val_data_loader = data.DataLoader(lm_val_set, batch_size=batch_size, num_workers=8,\n",
        "                                    shuffle=False)\n",
        "\n",
        "# You can try on a smaller training set by setting a smaller `sampling`.\n",
        "mt_train_set = MTDataset(train_src_sentences_list, src_vocab_set,\n",
        "                        train_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "mt_train_data_loader = data.DataLoader(mt_train_set, batch_size=batch_size,\n",
        "                                      num_workers=8, shuffle=True)\n",
        "\n",
        "mt_val_set = MTDataset(val_src_sentences_list, src_vocab_set,\n",
        "                      val_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "mt_val_data_loader = data.DataLoader(mt_val_set, batch_size=batch_size, num_workers=8,\n",
        "                                    shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEVw2xxRmFIC"
      },
      "source": [
        "Now we define the functions that will actually carry out the training process. You are strongly encouraged to read these carefully; doing so will likely save you time as you work on your model implementations.\n",
        "\n",
        "One important point to take note of here is that while in class we discussed using basic stochastic gradient descent (SGD) for our optimization method, in practice it is often better to use optimizers with adaptive learning rates, such as the Adam optimizer that we use here, the details of which you can find in [this paper](https://arxiv.org/abs/1412.6980)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "c6XZLkJbGXcC"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "class SimpleLossCompute:\n",
        "  \"\"\"A simple loss compute and train function.\"\"\"\n",
        "\n",
        "  def __init__(self, generator, criterion, opt=None):\n",
        "    self.generator = generator\n",
        "    self.criterion = criterion\n",
        "    self.opt = opt\n",
        "\n",
        "  def __call__(self, x, y, norm):\n",
        "    x = self.generator(x)\n",
        "    loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
        "                          y.contiguous().view(-1))\n",
        "    loss = loss / norm\n",
        "\n",
        "    if self.opt is not None:  # training mode\n",
        "      loss.backward()\n",
        "      self.opt.step()\n",
        "      self.opt.zero_grad()\n",
        "\n",
        "    return loss.data.item() * norm\n",
        "\n",
        "\n",
        "def run_epoch(data_loader, model, loss_compute, task, print_every):\n",
        "  \"\"\"Standard Training and Logging Function\"\"\"\n",
        "\n",
        "  total_tokens = 0\n",
        "  total_loss = 0\n",
        "\n",
        "  for i, (src_ids_BxT, src_lengths_B, trg_ids_BxL, trg_lengths_B) in enumerate(data_loader):\n",
        "    # We define some notations here to help you understand the loaded tensor\n",
        "    # shapes:\n",
        "    #   `B`: batch size\n",
        "    #   `T`: max sequence length of source sentences\n",
        "    #   `L`: max sequence length of target sentences; due to our preprocessing\n",
        "    #        in the beginning, `L` == `T` == 50\n",
        "    # An example of `src_ids_BxT` (when B = 2):\n",
        "    #   [[2, 4, 6, 7, ..., 4, 3, 0, 0, 0],\n",
        "    #    [2, 8, 6, 5, ..., 9, 5, 4, 3, 0]]\n",
        "    # The corresponding `src_lengths_B` would be [47, 49].\n",
        "    # Note that SOS_INDEX == 2, EOS_INDEX == 3, and PAD_INDEX = 0.\n",
        "\n",
        "    src_ids_BxT = src_ids_BxT.to(device)\n",
        "    src_lengths_B = src_lengths_B.to(device)\n",
        "    trg_ids_BxL = trg_ids_BxL.to(device)\n",
        "    del trg_lengths_B   # unused\n",
        "\n",
        "    if task == \"seq2seq\":\n",
        "      _, output = model(src_ids_BxT, trg_ids_BxL, src_lengths_B)\n",
        "\n",
        "      loss = loss_compute(x=output, y=trg_ids_BxL[:, 1:],\n",
        "                        norm=src_ids_BxT.size(0))\n",
        "      total_loss += loss\n",
        "      total_tokens += (trg_ids_BxL[:, 1:] != PAD_INDEX).data.sum().item()\n",
        "    elif task == \"lm\":\n",
        "      output = model(src_ids_BxT)\n",
        "\n",
        "      loss = loss_compute(x=output, y=trg_ids_BxL,\n",
        "                        norm=src_ids_BxT.size(0))\n",
        "      total_loss += loss\n",
        "      total_tokens += (trg_ids_BxL != PAD_INDEX).data.sum().item()\n",
        "    else:\n",
        "      raise ValueError(\"unknown task\")\n",
        "\n",
        "\n",
        "    if model.training and i % print_every == 0:\n",
        "      print(\"Epoch Step: %d Loss: %f\" % (i, loss / src_ids_BxT.size(0)))\n",
        "\n",
        "  return math.exp(total_loss / float(total_tokens))\n",
        "\n",
        "\n",
        "def train(model, num_epochs, learning_rate, train_data_loader, val_data_loader, task, print_every):\n",
        "  # Set `ignore_index` as PAD_INDEX so that pad tokens won't be included when\n",
        "  # computing the loss.\n",
        "  criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
        "  optim = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "  # Keep track of dev perplexity for each epoch.\n",
        "  dev_ppls = []\n",
        "\n",
        "  for epoch in range(1, 1+num_epochs):\n",
        "    print(\"Epoch\", epoch)\n",
        "\n",
        "    model.train()\n",
        "    train_ppl = run_epoch(data_loader=train_data_loader, model=model,\n",
        "                          loss_compute=SimpleLossCompute(model.generator,\n",
        "                                                         criterion, optim),\n",
        "                          task=task,\n",
        "                          print_every=print_every)\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "      dev_ppl = run_epoch(data_loader=val_data_loader, model=model,\n",
        "                          loss_compute=SimpleLossCompute(model.generator,\n",
        "                                                         criterion, None),\n",
        "                          task=task,\n",
        "                          print_every=print_every)\n",
        "      print(\"Validation perplexity: %f\" % dev_ppl)\n",
        "      dev_ppls.append(dev_ppl)\n",
        "\n",
        "  return dev_ppls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK6HQOWqnPEA"
      },
      "source": [
        "We provide a function for visualizing your models' learning curves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "s-yM1kPhG4K3"
      },
      "outputs": [],
      "source": [
        "def plot_perplexity(perplexities):\n",
        "  \"\"\"plot perplexities\"\"\"\n",
        "  plt.title(\"Perplexity per Epoch\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Perplexity\")\n",
        "  plt.plot(perplexities)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc9p7SGJndhk"
      },
      "source": [
        "This function takes a hidden state, performs a linear transformation on it, and finally takes a log softmax. Note the usage of this class within the above training functions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "flIf9QdoZL8S"
      },
      "outputs": [],
      "source": [
        "class Generator(nn.Module):\n",
        "  \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
        "  def __init__(self, hidden_size, vocab_size):\n",
        "    super(Generator, self).__init__()\n",
        "    self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "\n",
        "  def forward(self, x):\n",
        "    return F.log_softmax(self.proj(x), dim=-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60rKlVC6qqV0"
      },
      "source": [
        "Here we define decoding functions for performing inference with our Encoder-Decoder model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "89mr8sGhqo0w"
      },
      "outputs": [],
      "source": [
        "def greedy_decode(model, src_ids, src_lengths, max_len):\n",
        "  \"\"\"Greedily decode a sentence for EncoderDecoder.\"\"\"\n",
        "\n",
        "  with torch.no_grad():\n",
        "    encoder_hiddens, encoder_finals = model.encode(src_ids, src_lengths)\n",
        "    prev_y = torch.ones(1, 1).fill_(SOS_INDEX).type_as(src_ids)\n",
        "\n",
        "  output = []\n",
        "  hidden = None\n",
        "\n",
        "  for i in range(max_len):\n",
        "    with torch.no_grad():\n",
        "      hidden, outputs = model.decode(encoder_finals, prev_y, encoder_hiddens, hidden)\n",
        "      prob = model.generator(outputs[:, -1])\n",
        "\n",
        "    _, next_word = torch.max(prob, dim=1)\n",
        "    next_word = next_word.data.item()\n",
        "    output.append(next_word)\n",
        "    prev_y = torch.ones(1, 1).type_as(src_ids).fill_(next_word)\n",
        "\n",
        "  output = np.array(output)\n",
        "\n",
        "  # Cut off everything starting from </s>.\n",
        "  first_eos = np.where(output == EOS_INDEX)[0]\n",
        "  if len(first_eos) > 0:\n",
        "    output = output[:first_eos[0]]\n",
        "  return output\n",
        "\n",
        "def lookup_words(x, vocab):\n",
        "  return [vocab[i] for i in x]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGOLfO-WrI1_"
      },
      "source": [
        "You will use this function to visualize some examples once you have trained your translation model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "NKrsGqQgrKU3"
      },
      "outputs": [],
      "source": [
        "def print_examples(model, data_loader, n=3,\n",
        "                   max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS,\n",
        "                   src_vocab_set=src_vocab_set, trg_vocab_set=trg_vocab_set):\n",
        "  \"\"\"Prints `n` examples. Assumes batch size of 1.\"\"\"\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  for i, (src_ids, src_lengths, trg_ids, _) in enumerate(data_loader):\n",
        "    if isinstance(model, EncoderDecoder):\n",
        "      result = greedy_decode(model, src_ids.to(device), src_lengths.to(device),\n",
        "                             max_len=max_len)\n",
        "    else:\n",
        "      raise NotImplementedError(\"Unknown model type.\")\n",
        "\n",
        "    # remove <s>\n",
        "    src_ids = src_ids[0, 1:]\n",
        "    trg_ids = trg_ids[0, 1:]\n",
        "    # remove </s> and <pad>\n",
        "    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
        "    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
        "\n",
        "    print(\"Example #%d\" % (i + 1))\n",
        "    print(\"Src : \", \" \".join(lookup_words(src_ids, vocab=src_vocab_set)))\n",
        "    print(\"Trg : \", \" \".join(lookup_words(trg_ids, vocab=trg_vocab_set)))\n",
        "    print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab_set)))\n",
        "    print()\n",
        "\n",
        "    if i == n - 1:\n",
        "      break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXQFpduzr3ay"
      },
      "source": [
        "The following function will allow you to evaluate your translation model's BLEU score on a test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "jegcU9-ur1jK"
      },
      "outputs": [],
      "source": [
        "import sacrebleu\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "def compute_BLEU(model, data_loader):\n",
        "  bleu_score = []\n",
        "\n",
        "  model.eval()\n",
        "  for src_ids, src_lengths, trg_ids, _ in tqdm(data_loader):\n",
        "    if isinstance(model, EncoderDecoder):\n",
        "      result = greedy_decode(model, src_ids.to(device), src_lengths.to(device),\n",
        "                             max_len=MAX_SENT_LENGTH_PLUS_SOS_EOS)\n",
        "    else:\n",
        "      raise NotImplementedError(\"Unknown model type.\")\n",
        "\n",
        "    # remove <s>\n",
        "    src_ids = src_ids[0, 1:]\n",
        "    trg_ids = trg_ids[0, 1:]\n",
        "    # remove </s> and <pad>\n",
        "    src_ids = src_ids[:np.where(src_ids == EOS_INDEX)[0][0]]\n",
        "    trg_ids = trg_ids[:np.where(trg_ids == EOS_INDEX)[0][0]]\n",
        "\n",
        "    pred = \" \".join(lookup_words(result, vocab=trg_vocab_set))\n",
        "    targ = \" \".join(lookup_words(trg_ids, vocab=trg_vocab_set))\n",
        "\n",
        "    bleu_score.append(sacrebleu.raw_corpus_bleu([pred], [[targ]], .01).score)\n",
        "\n",
        "  return bleu_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75Xar0RA0HCZ"
      },
      "source": [
        "# **Part 2: Recurrent Neural Network (RNN)**\n",
        "\n",
        "In this part, you will implement a vanilla RNN language model. You are not allowed to use the PyTorch built-in RNN module (or the corresponding LSTM and GRU modules), but you may use the RNNCell (https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html) module (or the LSTMCell/GRUCell modules)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "GOy71ueb0I0G"
      },
      "outputs": [],
      "source": [
        "class RNN(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, src_embed, generator):\n",
        "      \"\"\"\n",
        "      Inputs:\n",
        "        - `input_size`: a positive integer corresponding to the size of the\n",
        "            word embeddings\n",
        "        - `hidden_size`: a positive integer representing the dimensionality of\n",
        "            the RNN's hidden state vector\n",
        "        - `src_embed`: an nn.Embedding object representing the lookup table for\n",
        "            input (source) sentences\n",
        "        - `generator`: a `Generator` object. Essentially a linear mapping\n",
        "            followed by a softmax. You should not call it within this class; it\n",
        "            is called in the SimpleLossCompute class above\n",
        "      \"\"\"\n",
        "      super(RNN, self).__init__()\n",
        "      # `input_size`, `hidden_size`, and `output_size` are all int.\n",
        "\n",
        "      self.hidden_size = hidden_size\n",
        "      self.src_embed = src_embed\n",
        "      self.generator = generator\n",
        "      # hint: unless you choose to implement the RNN update equations yourself\n",
        "      #       you will want a `self.rnn` module that does that for you, which\n",
        "      #       is where the RNNCell/LSTMCell/GRUCell modules come in handy\n",
        "\n",
        "      self.rnn = nn.RNNCell(input_size, hidden_size)\n",
        "      ###\n",
        "\n",
        "    def init_hidden(self, batch_size):\n",
        "      \"\"\"\n",
        "      Input:\n",
        "        - `batch_size`: a positive integer\n",
        "\n",
        "      Returns:\n",
        "        - `hidden`: a 2d-tensor of shape (batch_size, hidden_size) representing\n",
        "            the initial hidden state of the RNN\n",
        "      \"\"\"\n",
        "      # Use to initialize hidden state everytime before running a sentence.\n",
        "      hidden = torch.zeros(batch_size, self.hidden_size).to(device)\n",
        "      return hidden\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "      \"\"\"\n",
        "      Given a sequence of words (represented as IDs), compute and return the\n",
        "      hidden state at each timestep (equivalently, for each input word).\n",
        "      Input:\n",
        "        - `input_ids`: a 2d-tensor of shape\n",
        "           (batch_size, MAX_SENT_LENGTH_PLUS_SOS_EOS) representing a batch of\n",
        "           sentences from the dataset (with IDs instead of words)\n",
        "\n",
        "      Returns:\n",
        "        - `hiddens`: a 3d-tensor of shape\n",
        "            (batch_size, MAX_SENT_LENGTH_PLUS_SOS_EOS, hidden_size) representing\n",
        "            the hidden state of the model at each timestep\n",
        "      \"\"\"\n",
        "      # hint: pay close attention to the shapes of your tensors; you may find\n",
        "      #       pytorch's `permute()` method for tensors useful\n",
        "\n",
        "      h_t = self.init_hidden(input_ids.size(0))\n",
        "      input_ids = input_ids.permute(1,0)\n",
        "      hiddens = []\n",
        "      for id in input_ids:\n",
        "        id_embed = self.src_embed(id)\n",
        "        h_t = self.rnn(id_embed, h_t)\n",
        "        hiddens.append(h_t)\n",
        "      hiddens = torch.stack(hiddens)\n",
        "      hiddens = hiddens.permute(1,0,2)\n",
        "      ###\n",
        "\n",
        "      return hiddens\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRB8Re7eoMZF"
      },
      "source": [
        "Once you have implemented your model, run this cell to train and evaluate it. Note that the hyperparameters chosen here (including `learning_rate`) are not necessarily optimal—you may want to adjust them to improve performance. A simple one-layer implementation of a vanilla RNN should yield a perplexity in the 70s or 80s, but you can do better by adding layers, implementing a GRU/LSTM, and/or optimizing hyperparameters.\n",
        "\n",
        "NOTE THAT IT MIGHT TAKE A WHILE (13 MINS) TO TRAIN FOR 10 EPOCHS (plan accordingly)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-FSlqG1tVsiJ",
        "outputId": "28cf5744-920f-4cb5-867f-12f7b017720d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "Epoch Step: 0 Loss: 170.723511\n",
            "Epoch Step: 100 Loss: 98.606956\n",
            "Epoch Step: 200 Loss: 92.112328\n",
            "Epoch Step: 300 Loss: 94.386887\n",
            "Epoch Step: 400 Loss: 86.887627\n",
            "Epoch Step: 500 Loss: 90.375404\n",
            "Epoch Step: 600 Loss: 86.800941\n",
            "Epoch Step: 700 Loss: 85.569344\n",
            "Epoch Step: 800 Loss: 84.743286\n",
            "Validation perplexity: 105.107479\n",
            "Epoch 2\n",
            "Epoch Step: 0 Loss: 70.475731\n",
            "Epoch Step: 100 Loss: 81.022896\n",
            "Epoch Step: 200 Loss: 70.150269\n",
            "Epoch Step: 300 Loss: 86.193031\n",
            "Epoch Step: 400 Loss: 83.528687\n",
            "Epoch Step: 500 Loss: 79.004494\n",
            "Epoch Step: 600 Loss: 73.402657\n",
            "Epoch Step: 700 Loss: 76.586395\n",
            "Epoch Step: 800 Loss: 76.959671\n",
            "Validation perplexity: 91.145006\n",
            "Epoch 3\n",
            "Epoch Step: 0 Loss: 79.773499\n",
            "Epoch Step: 100 Loss: 76.576363\n",
            "Epoch Step: 200 Loss: 76.964050\n",
            "Epoch Step: 300 Loss: 80.145714\n",
            "Epoch Step: 400 Loss: 72.587502\n",
            "Epoch Step: 500 Loss: 71.496239\n",
            "Epoch Step: 600 Loss: 78.213127\n",
            "Epoch Step: 700 Loss: 78.679375\n",
            "Epoch Step: 800 Loss: 76.918732\n",
            "Validation perplexity: 87.337200\n",
            "Epoch 4\n",
            "Epoch Step: 0 Loss: 70.161041\n",
            "Epoch Step: 100 Loss: 77.515320\n",
            "Epoch Step: 200 Loss: 76.064079\n",
            "Epoch Step: 300 Loss: 77.332382\n",
            "Epoch Step: 400 Loss: 74.540985\n",
            "Epoch Step: 500 Loss: 73.283356\n",
            "Epoch Step: 600 Loss: 73.331131\n",
            "Epoch Step: 700 Loss: 77.943764\n",
            "Epoch Step: 800 Loss: 71.124367\n",
            "Validation perplexity: 85.321878\n",
            "Epoch 5\n",
            "Epoch Step: 0 Loss: 66.264015\n",
            "Epoch Step: 100 Loss: 80.010170\n",
            "Epoch Step: 200 Loss: 65.477982\n",
            "Epoch Step: 300 Loss: 68.265228\n",
            "Epoch Step: 400 Loss: 66.349510\n",
            "Epoch Step: 500 Loss: 73.172813\n",
            "Epoch Step: 600 Loss: 73.860695\n",
            "Epoch Step: 700 Loss: 72.412949\n",
            "Epoch Step: 800 Loss: 74.330849\n",
            "Validation perplexity: 85.182256\n",
            "Epoch 6\n",
            "Epoch Step: 0 Loss: 63.034771\n",
            "Epoch Step: 100 Loss: 73.361130\n",
            "Epoch Step: 200 Loss: 62.502308\n",
            "Epoch Step: 300 Loss: 69.519646\n",
            "Epoch Step: 400 Loss: 76.156303\n",
            "Epoch Step: 500 Loss: 73.705910\n",
            "Epoch Step: 600 Loss: 71.488678\n",
            "Epoch Step: 700 Loss: 69.198296\n",
            "Epoch Step: 800 Loss: 75.826302\n",
            "Validation perplexity: 85.753687\n",
            "Epoch 7\n",
            "Epoch Step: 0 Loss: 72.024986\n",
            "Epoch Step: 100 Loss: 66.869598\n",
            "Epoch Step: 200 Loss: 68.872490\n",
            "Epoch Step: 300 Loss: 73.141731\n",
            "Epoch Step: 400 Loss: 66.640015\n",
            "Epoch Step: 500 Loss: 71.625885\n",
            "Epoch Step: 600 Loss: 73.656769\n",
            "Epoch Step: 700 Loss: 73.324478\n",
            "Epoch Step: 800 Loss: 66.587700\n",
            "Validation perplexity: 86.815831\n",
            "Epoch 8\n",
            "Epoch Step: 0 Loss: 66.881691\n",
            "Epoch Step: 100 Loss: 70.389221\n",
            "Epoch Step: 200 Loss: 71.036713\n",
            "Epoch Step: 300 Loss: 69.185913\n",
            "Epoch Step: 400 Loss: 69.870323\n",
            "Epoch Step: 500 Loss: 73.139565\n",
            "Epoch Step: 600 Loss: 64.301811\n",
            "Epoch Step: 700 Loss: 73.530724\n",
            "Epoch Step: 800 Loss: 67.543434\n",
            "Validation perplexity: 88.109480\n",
            "Epoch 9\n",
            "Epoch Step: 0 Loss: 68.198746\n",
            "Epoch Step: 100 Loss: 65.743477\n",
            "Epoch Step: 200 Loss: 72.604507\n",
            "Epoch Step: 300 Loss: 68.078674\n",
            "Epoch Step: 400 Loss: 68.039787\n",
            "Epoch Step: 500 Loss: 71.651817\n",
            "Epoch Step: 600 Loss: 67.568222\n",
            "Epoch Step: 700 Loss: 74.524071\n",
            "Epoch Step: 800 Loss: 71.362755\n",
            "Validation perplexity: 90.111951\n",
            "Epoch 10\n",
            "Epoch Step: 0 Loss: 70.255135\n",
            "Epoch Step: 100 Loss: 64.773590\n",
            "Epoch Step: 200 Loss: 65.792854\n",
            "Epoch Step: 300 Loss: 64.719398\n",
            "Epoch Step: 400 Loss: 66.810814\n",
            "Epoch Step: 500 Loss: 67.145874\n",
            "Epoch Step: 600 Loss: 68.167252\n",
            "Epoch Step: 700 Loss: 71.294113\n",
            "Epoch Step: 800 Loss: 68.833252\n",
            "Validation perplexity: 91.804819\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "embed_size = 256   # Each word will be represented as a `embed_size`-dim vector.\n",
        "hidden_size = 256\n",
        "\n",
        "# model itself\n",
        "rnn_lm = RNN(input_size=embed_size,\n",
        "             hidden_size=hidden_size,\n",
        "             src_embed=nn.Embedding(len(trg_vocab_set), embed_size),\n",
        "             generator=Generator(hidden_size, len(trg_vocab_set))).to(device)\n",
        "\n",
        "# list of epoch perplexities from training\n",
        "lm_dev_ppls = train(rnn_lm, num_epochs=10,\n",
        "                    learning_rate=1e-3,\n",
        "                    train_data_loader=lm_train_data_loader,\n",
        "                    val_data_loader=lm_val_data_loader,\n",
        "                    task=\"lm\", print_every=100)\n",
        "\n",
        "plot_perplexity(lm_dev_ppls)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fOArV2r9Piz"
      },
      "source": [
        "# **Part 3: Seq2Seq Model**\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mA9JfWiK9eoL"
      },
      "source": [
        "In this part of the lab, you will explore seq2seq to perform a machine translation task. The main task is to implement the naive encoder-decoder architecture without attention.\n",
        "\n",
        "In machine translation (MT), your goal is to translate the correct sentence meaning into another language. In our case, we want to translate Vietnamese sentences into English sentences. See the diagram below for an illustration of how the translation process works with an encoder-decoder architecture.\n",
        "\n",
        "Note that this default Encoder-Decoder sequence-to-sequence model that you will implement is not at all good enough to function as a realistic machine translation system.\n",
        "For those interested, feel free to experiment with the model to try to improve it!\n",
        "\n",
        "Some possible suggestions include:\n",
        "- Playing around with basic hyperparameters (model size, dropout, learning rate, etc.)\n",
        "- Experimenting with different RNN Cells (GRU/LSTM)\n",
        "- Exploring attention-based models (quite difficult)\n",
        "- Using beam search instead of greedy search (moderately difficult)\n",
        "\n",
        "Feel free to alter the signatures / write helper functions for the below classes.\n",
        "\n",
        "![picture](https://drive.google.com/uc?id=1VQMgKh6AdxcJZiw7qO7cE_MHyiAAu62b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kb5gQEp7oVdi"
      },
      "source": [
        "## Encoder\n",
        "\n",
        "We will start with a single-layer unidirectional GRU. You are free to try bidirectional and stack more layers. Note that we are now including *dropout* in our model. Dropout is essentially a regularization technique in which a specified proportion of the model parameters are randomly ignored during a given forward and backward pass of the model. If you want a more detailed explanation, see [this paper](https://arxiv.org/abs/1409.2329) which discusses dropout in the context of RNNs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "dnwVGDVkoPt0"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, dropout=0.):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      - `input_size`: an int representing the RNN input size.\n",
        "      - `hidden_size`: an int representing the RNN hidden size.\n",
        "      - `dropout`: a float representing the dropout rate during training. Note\n",
        "          that for 1-layer RNN this has no effect since dropout only applies to\n",
        "          outputs of intermediate layers.\n",
        "    \"\"\"\n",
        "    super(Encoder, self).__init__()\n",
        "    self.rnn = nn.GRU(input_size, hidden_size, num_layers=1, batch_first=True,\n",
        "                      dropout=dropout, bidirectional=False)\n",
        "\n",
        "  def forward(self, inputs, lengths):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n",
        "          representing a batch of padded embedded word vectors of source\n",
        "          sentences.\n",
        "      - `lengths`: a 1d-tensor of shape (batch_size,) representing the sequence\n",
        "          lengths of `inputs`.\n",
        "\n",
        "    Returns:\n",
        "      - `outputs`: a 3d-tensor of shape\n",
        "        (batch_size, max_seq_length, hidden_size).\n",
        "      - `finals`: a 3d-tensor of shape (num_layers, batch_size, hidden_size).\n",
        "      Hint: `outputs` and `finals` are both standard GRU outputs. Check:\n",
        "      https://pytorch.org/docs/stable/nn.html#gru\n",
        "    \"\"\"\n",
        "    # Our variable-length inputs are padded to the same length for batching\n",
        "    # Here we \"pack\" them for computational efficiency (see note below)\n",
        "    packed = pack_padded_sequence(inputs, lengths.cpu(), batch_first=True,\n",
        "                                  enforce_sorted=False)\n",
        "    outputs, finals = self.rnn(packed)\n",
        "    outputs, _ = pad_packed_sequence(outputs, batch_first=True,\n",
        "                                     total_length=MAX_SENT_LENGTH_PLUS_SOS_EOS)\n",
        "    return outputs, finals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hxs73iWLLXOx"
      },
      "source": [
        "Note: For a clear explanation of padding and packing, see the second answer to this [stackoverflow question](https://stackoverflow.com/questions/51030782/why-do-we-pack-the-sequences-in-pytorch)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWFWtxhbpSl-"
      },
      "source": [
        "## Decoder\n",
        "\n",
        "The decoder is a conditional GRU. Rather than starting with an empty state like the encoder, its initial hidden state results from a projection of the encoder final vector."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "JYT0BlfYUJXj"
      },
      "outputs": [],
      "source": [
        "class Decoder(nn.Module):\n",
        "  \"\"\"An RNN decoder. Optionally add attention using the scaffolding function. \"\"\"\n",
        "\n",
        "  def __init__(self, input_size, hidden_size, dropout=0.):\n",
        "    \"\"\"\n",
        "      Inputs:\n",
        "        - `input_size`, `hidden_size`, and `dropout` the same as in Encoder.\n",
        "    \"\"\"\n",
        "    super(Decoder, self).__init__()\n",
        "\n",
        "    # hint 1: while the encoder just needed a single RNN layer, more will be\n",
        "    #         required for the decoder.\n",
        "    # hint 2: think about what you'll need in init_hidden(self, encoder_finals)\n",
        "    # hint 3: what will you use to compute the pre_output (see docstring of\n",
        "    #         forward function)?\n",
        "\n",
        "    self.rnn = nn.GRU(input_size, hidden_size, batch_first = True, dropout = dropout, bidirectional=False)\n",
        "    self.linear = nn.Linear(hidden_size, hidden_size, bias = True)\n",
        "    self.dropout = nn.Dropout(p = dropout)\n",
        "    self.preoutput = nn.Linear(hidden_size + input_size, hidden_size, bias = False)\n",
        "\n",
        "    ###\n",
        "\n",
        "  def forward_step(self, prev_embed, hidden):\n",
        "    \"\"\"Helper function for forward below:\n",
        "       Perform a single decoder step (1 word).\n",
        "\n",
        "       Inputs:\n",
        "      - `prev_embed`: a 3d-tensor of shape (batch_size, 1, embed_size)\n",
        "          representing the padded embedded word vectors at this step in training\n",
        "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size) representing\n",
        "          the current hidden state.\n",
        "\n",
        "      Returns:\n",
        "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size)\n",
        "          representing the current decoder hidden state.\n",
        "      - `pre_output`: a 3d-tensor of shape (batch_size, 1, hidden_size)\n",
        "          representing the total decoder output for one step\n",
        "    \"\"\"\n",
        "    # hint: you'll want to do more here than just run self.rnn (think about\n",
        "    #       what you should do to the output of the self.rnn in order to\n",
        "    #       compute the `pre_output`)\n",
        "\n",
        "    output, hidden = self.rnn(prev_embed, hidden)\n",
        "    cat_output = torch.cat([prev_embed, output], dim=2)\n",
        "    pre_dropout = self.dropout(cat_output)\n",
        "    pre_output = self.preoutput(pre_dropout)\n",
        "\n",
        "    ###\n",
        "\n",
        "    return hidden, pre_output\n",
        "\n",
        "  def forward(self, inputs, encoder_finals, encoder_hiddens, hidden=None, max_len=None):\n",
        "    \"\"\"Unroll the decoder one step at a time.\n",
        "\n",
        "    Inputs:\n",
        "      - `inputs`: a 3d-tensor of shape (batch_size, max_seq_length, embed_size)\n",
        "          representing a batch of padded embedded word vectors of target\n",
        "          sentences (for teacher-forcing during training). (during evaluation,\n",
        "          we instead have the model's previously-predicted best word).\n",
        "      - `encoder_finals`: a 3d-tensor of shape\n",
        "          (num_enc_layers, batch_size, hidden_size) representing the final\n",
        "          encoder hidden states used to initialize the initial decoder hidden\n",
        "          states.\n",
        "      - `encoder_hiddens` (only needed for attention): a 3d-tensor of shape\n",
        "          (batch_size, max_seq_length, hidden_size) representing the hidden state\n",
        "          at each point in the encoder sequence.\n",
        "      - `hidden`: a 3d-tensor of shape (1, batch_size, hidden_size) representing\n",
        "          the value to be used to initialize the initial decoder hidden states.\n",
        "          If None, then use `encoder_finals`.\n",
        "      - `max_len`: an int representing the maximum decoding length.\n",
        "\n",
        "    Returns:\n",
        "      - `hidden`: a 3d-tensor of shape\n",
        "          (num_layers, batch_size, hidden_size) representing the final hidden\n",
        "          state for each element in the batch.\n",
        "      - `pre_output_vectors`: a 3d-tensor of shape\n",
        "          (batch_size, max_len, hidden_size) representing the raw decoder\n",
        "          outputs (before mapping to a `trg_vocab_size`-dim vector).\n",
        "    \"\"\"\n",
        "\n",
        "    # The maximum number of steps to unroll the RNN.\n",
        "    if max_len is None:\n",
        "      max_len = inputs.size(1)\n",
        "\n",
        "    # Initialize decoder hidden state.\n",
        "    if hidden is None:\n",
        "      hidden = self.init_hidden(encoder_finals)\n",
        "\n",
        "    # hint: you'll want to keep track of the `pre_output` for each timestep,\n",
        "    #       but you only need the final `hidden` state\n",
        "\n",
        "    pre_output_vectors = []\n",
        "    for i in range(max_len):\n",
        "      embed = inputs[:, i].unsqueeze(1)\n",
        "      hidden, pre_output = self.forward_step(embed, hidden)\n",
        "      pre_output_vectors.append(pre_output)\n",
        "    pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n",
        "    ###\n",
        "\n",
        "    return hidden, pre_output_vectors\n",
        "\n",
        "  def init_hidden(self, encoder_finals):\n",
        "    \"\"\"Use encoder final hidden state to initialize decoder's first hidden\n",
        "       state.\n",
        "\n",
        "       Input: `encoder_finals` is same as in forward()\n",
        "\n",
        "       Returns:\n",
        "         - `decoder_init_hiddens`: a 3d-tensor of shape\n",
        "              (num_layers, batch_size, hidden_size) representing the initial\n",
        "              hidden state of the decoder for each element in the batch\n",
        "    \"\"\"\n",
        "    # hint: think about whether or not an activation function is needed here\n",
        "\n",
        "    decoder_init_hiddens = torch.tanh(self.linear(encoder_finals))\n",
        "    ###\n",
        "    return decoder_init_hiddens\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AH0VdHE2_x1k"
      },
      "source": [
        "## Encoder-Decoder\n",
        "\n",
        "Here we define the high level encoder-decoder class to wrap up sub-models, including encoder, decoder, generator, and src/trg embeddings. There are solutions in which you do not need to write any code for this module, but your implementation of the above moudles might require some code to be written."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "nNBaAYB_oHxG"
      },
      "outputs": [],
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "  \"\"\"A standard Encoder-Decoder architecture without attention.\n",
        "  \"\"\"\n",
        "  def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
        "    \"\"\"\n",
        "    Inputs:\n",
        "      - `encoder`: an `Encoder` object.\n",
        "      - `decoder`: an `Decoder` object.\n",
        "      - `src_embed`: an nn.Embedding object representing the lookup table for\n",
        "          input (source) sentences.\n",
        "      - `trg_embed`: an nn.Embedding object representing the lookup table for\n",
        "          output (target) sentences.\n",
        "      - `generator`: a `Generator` object. Essentially a linear mapping. See\n",
        "          the next code cell.\n",
        "    \"\"\"\n",
        "    super(EncoderDecoder, self).__init__()\n",
        "\n",
        "    self.encoder = encoder\n",
        "    self.decoder = decoder\n",
        "    self.src_embed = src_embed\n",
        "    self.trg_embed = trg_embed\n",
        "    self.generator = generator\n",
        "\n",
        "  def forward(self, src_ids, trg_ids, src_lengths):\n",
        "    \"\"\"Take in and process masked source and target sequences.\n",
        "\n",
        "    Inputs:\n",
        "      `src_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
        "        a batch of source sentences of word ids.\n",
        "      `trg_ids`: a 2d-tensor of shape (batch_size, max_seq_length) representing\n",
        "        a batch of target sentences of word ids.\n",
        "      `src_lengths`: a 1d-tensor of shape (batch_size,) representing the\n",
        "        sequence length of `src_ids`.\n",
        "\n",
        "    Returns the decoder outputs, see the above cell.\n",
        "    \"\"\"\n",
        "    encoder_hiddens, encoder_finals = self.encode(src_ids, src_lengths)\n",
        "    return self.decode(encoder_finals, trg_ids[:, :-1], encoder_hiddens)\n",
        "\n",
        "  def encode(self, src_ids, src_lengths):\n",
        "    return self.encoder(self.src_embed(src_ids), src_lengths)\n",
        "\n",
        "  def decode(self, encoder_finals, trg_ids, encoder_hiddens, decoder_hidden=None):\n",
        "    return self.decoder(self.trg_embed(trg_ids), encoder_finals, encoder_hiddens, decoder_hidden)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAGHeLyGp5bA"
      },
      "source": [
        "Once you have implemented your model, run this cell to train and evaluate your model. Note that the hyperparameters chosen here (including `learning_rate`) are not necessarily optimal—you may want to adjust them to improve performance. A reasonable perplexity here would be in the low- to mid-30s after 10 epochs of training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j7ueW-ZJp4RD",
        "outputId": "dded2c1a-b838-49d1-f09c-6005e5a28a12"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/rnn.py:71: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1\n",
            "Epoch Step: 0 Loss: 179.951050\n",
            "Epoch Step: 100 Loss: 104.124367\n"
          ]
        }
      ],
      "source": [
        "# Hyperparameters for contructing the encoder-decoder model.\n",
        "\n",
        "embed_size = 256   # Each word will be represented as a `embed_size`-dim vector.\n",
        "hidden_size = 256  # RNN hidden size.\n",
        "dropout = 0.2\n",
        "\n",
        "# model itsef\n",
        "pure_seq2seq = EncoderDecoder(\n",
        "  encoder=Encoder(embed_size, hidden_size, dropout=dropout),\n",
        "  decoder=Decoder(embed_size, hidden_size, dropout=dropout),\n",
        "  src_embed=nn.Embedding(len(src_vocab_set), embed_size),\n",
        "  trg_embed=nn.Embedding(len(trg_vocab_set), embed_size),\n",
        "  generator=Generator(hidden_size, len(trg_vocab_set))).to(device)\n",
        "\n",
        "# Start training. The returned `dev_ppls` is a list of dev perplexity for each\n",
        "# epoch.\n",
        "pure_dev_ppls = train(pure_seq2seq, num_epochs=10, learning_rate=1e-3,\n",
        "                      train_data_loader=mt_train_data_loader,\n",
        "                      val_data_loader=mt_val_data_loader,\n",
        "                      task=\"seq2seq\", print_every=100)\n",
        "\n",
        "plot_perplexity(pure_dev_ppls)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljzZFE51rj5d"
      },
      "source": [
        "Run the following cell to visualize some of the translations produced by your model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1DcDx_xGriSP"
      },
      "outputs": [],
      "source": [
        "example_set = MTDataset(val_src_sentences_list, src_vocab_set,\n",
        "                        val_trg_sentences_list, trg_vocab_set)\n",
        "example_data_loader = data.DataLoader(mt_val_set, batch_size=1, num_workers=1,\n",
        "                                      shuffle=True)\n",
        "\n",
        "print_examples(pure_seq2seq, example_data_loader, n=6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Mr6dQSVsP7Z"
      },
      "source": [
        "For translation, BLEU score gives a better measure of performance than perplexity. Run this cell to compute your model's BLEU score on a test dataset. A reasonable BLEU score would be something around 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cCqdcglgsMiW"
      },
      "outputs": [],
      "source": [
        "test_set = MTDataset(test_src_sentences_list, src_vocab_set,\n",
        "                     test_trg_sentences_list, trg_vocab_set, sampling=1.)\n",
        "test_data_loader = data.DataLoader(test_set, batch_size=1, num_workers=8,\n",
        "                                   shuffle=False)\n",
        "\n",
        "print(np.mean(compute_BLEU(pure_seq2seq, test_data_loader)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UV9qsM_sW8G5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
